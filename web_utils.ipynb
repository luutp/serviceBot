{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing google_images_download module \n",
    "from google_images_download import google_images_download\n",
    "import utils as utils\n",
    "from utils import get_varargin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadimages(query, **kwargs): \n",
    "    # keywords is the search query \n",
    "    # format is the image file format \n",
    "    # limit is the number of images to be downloaded \n",
    "    # print urs is to print the image file url \n",
    "    # size is the image size which can \n",
    "    # be specified manually (\"large, medium, icon\") \n",
    "    # aspect ratio denotes the height width ratio \n",
    "    # of images to download. (\"tall, square, wide, panoramic\") \n",
    "    output_dir = get_varargin(kwargs, 'output_directory', os.getcwd())\n",
    "    nb_images = get_varargin(kwargs, 'nb_images', 4)\n",
    "    img_size = get_varargin(kwargs, 'size', 'medium')\n",
    "    \n",
    "    arguments = {\"keywords\" : query, \n",
    "                 \"format\" : \"jpg\", \n",
    "                 \"limit\": nb_images, \n",
    "                 \"print_urls\" : True,\n",
    "                 'output_directory' : output_dir,\n",
    "                 \"size\" : img_size} \n",
    "    # creating object \n",
    "    response = google_images_download.googleimagesdownload()  \n",
    "    try: \n",
    "        response.download(arguments) \n",
    "      \n",
    "    # Handling File NotFound Error     \n",
    "    except FileNotFoundError:  \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item no.: 1 --> Item name = dog\n",
      "Evaluating...\n",
      "Starting Download...\n",
      "Image URL: https://d17fnq9dkz9hgj.cloudfront.net/breed-uploads/2018/09/dog-landing-hero-lg.jpg?bust=1536935129&width=1080\n",
      "Completed Image ====> 1.dog-landing-hero-lg.jpg\n",
      "Image URL: https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/12234558/Chinook-On-White-03.jpg\n",
      "Completed Image ====> 2.Chinook-On-White-03.jpg\n",
      "Image URL: https://www.petmd.com/sites/default/files/Acute-Dog-Diarrhea-47066074.jpg\n",
      "Completed Image ====> 3.Acute-Dog-Diarrhea-47066074.jpg\n",
      "Image URL: https://www.petmd.com/sites/default/files/senior-golden-retriever-with-ball-picture-id488657289.jpg\n",
      "Completed Image ====> 4.senior-golden-retriever-with-ball-picture-id488657289.jpg\n",
      "Image URL: https://boygeniusreport.files.wordpress.com/2016/11/puppy-dog.jpg?quality=98&strip=all&w=782\n",
      "Completed Image ====> 5.puppy-dog.jpg\n",
      "\n",
      "Errors: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Driver Code \n",
    "search_queries = ['dog']\n",
    "# output_dir = 'G:\\\\OneDrive\\\\luuPyCode\\\\MaskRCNN\\\\images'\n",
    "output_dir = os.getcwd()\n",
    "for query in search_queries: \n",
    "    downloadimages(query, nb_images = 5, output_directory = output_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from math import trunc\n",
    "from PIL import Image as PILImage\n",
    "from PIL import ImageDraw as PILImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset json\n",
    "class CocoDataset():\n",
    "    def __init__(self, annotation_path, image_dir):\n",
    "        self.annotation_path = annotation_path\n",
    "        self.image_dir = image_dir\n",
    "        self.colors = ['blue', 'purple', 'red', 'green', 'orange', 'salmon', 'pink', 'gold',\n",
    "                       'orchid', 'slateblue', 'limegreen', 'seagreen', 'darkgreen', 'olive',\n",
    "                       'teal', 'aquamarine', 'steelblue', 'powderblue', 'dodgerblue', 'navy',\n",
    "                       'magenta', 'sienna', 'maroon']\n",
    "\n",
    "        json_file = open(self.annotation_path)\n",
    "        self.coco = json.load(json_file)\n",
    "        json_file.close()\n",
    "\n",
    "        self.process_info()\n",
    "        self.process_licenses()\n",
    "        self.process_categories()\n",
    "        self.process_images()\n",
    "        self.process_segmentations()\n",
    "\n",
    "    def display_info(self):\n",
    "        print('Dataset Info:')\n",
    "        print('=============')\n",
    "        if self.info is None:\n",
    "            return\n",
    "        for key, item in self.info.items():\n",
    "            print('  {}: {}'.format(key, item))\n",
    "\n",
    "        requirements = [['description', str],\n",
    "                        ['url', str],\n",
    "                        ['version', str],\n",
    "                        ['year', int],\n",
    "                        ['contributor', str],\n",
    "                        ['date_created', str]]\n",
    "        for req, req_type in requirements:\n",
    "            if req not in self.info:\n",
    "                print('ERROR: {} is missing'.format(req))\n",
    "            elif type(self.info[req]) != req_type:\n",
    "                print('ERROR: {} should be type {}'.format(req, str(req_type)))\n",
    "        print('')\n",
    "\n",
    "    def display_licenses(self):\n",
    "        print('Licenses:')\n",
    "        print('=========')\n",
    "\n",
    "        if self.licenses is None:\n",
    "            return\n",
    "        requirements = [['id', int],\n",
    "                        ['url', str],\n",
    "                        ['name', str]]\n",
    "        for license in self.licenses:\n",
    "            for key, item in license.items():\n",
    "                print('  {}: {}'.format(key, item))\n",
    "            for req, req_type in requirements:\n",
    "                if req not in license:\n",
    "                    print('ERROR: {} is missing'.format(req))\n",
    "                elif type(license[req]) != req_type:\n",
    "                    print('ERROR: {} should be type {}'.format(\n",
    "                        req, str(req_type)))\n",
    "            print('')\n",
    "        print('')\n",
    "\n",
    "    def display_categories(self):\n",
    "        print('Categories:')\n",
    "        print('=========')\n",
    "        for sc_key, sc_val in self.super_categories.items():\n",
    "            print('  super_category: {}'.format(sc_key))\n",
    "            for cat_id in sc_val:\n",
    "                print('    id {}: {}'.format(\n",
    "                    cat_id, self.categories[cat_id]['name']))\n",
    "            print('')\n",
    "\n",
    "    def display_image(self, image_id, show_polys=True, show_bbox=True, show_crowds=True, use_url=False):\n",
    "        print('Image:')\n",
    "        print('======')\n",
    "        if image_id == 'random':\n",
    "            image_id = random.choice(list(self.images.keys()))\n",
    "\n",
    "        # Print the image info\n",
    "        image = self.images[image_id]\n",
    "        for key, val in image.items():\n",
    "            print('  {}: {}'.format(key, val))\n",
    "\n",
    "        # Open the image\n",
    "        if use_url:\n",
    "            image_path = image['coco_url']\n",
    "            response = requests.get(image_path)\n",
    "            image = PILImage.open(BytesIO(response.content))\n",
    "\n",
    "        else:\n",
    "            image_path = os.path.join(self.image_dir, image['file_name'])\n",
    "            image = PILImage.open(image_path)\n",
    "\n",
    "        # Calculate the size and adjusted display size\n",
    "        max_width = 600\n",
    "        image_width, image_height = image.size\n",
    "        adjusted_width = min(image_width, max_width)\n",
    "        adjusted_ratio = adjusted_width / image_width\n",
    "        adjusted_height = adjusted_ratio * image_height\n",
    "\n",
    "        # Create list of polygons to be drawn\n",
    "        polygons = {}\n",
    "        bbox_polygons = {}\n",
    "        rle_regions = {}\n",
    "        poly_colors = {}\n",
    "        bbox_categories = {}\n",
    "        print('  segmentations ({}):'.format(\n",
    "            len(self.segmentations[image_id])))\n",
    "        for i, segm in enumerate(self.segmentations[image_id]):\n",
    "            polygons_list = []\n",
    "            if segm['iscrowd'] != 0:\n",
    "                # Gotta decode the RLE\n",
    "                px = 0\n",
    "                x, y = 0, 0\n",
    "                rle_list = []\n",
    "                for j, counts in enumerate(segm['segmentation']['counts']):\n",
    "                    if j % 2 == 0:\n",
    "                        # Empty pixels\n",
    "                        px += counts\n",
    "                    else:\n",
    "                        # Need to draw on these pixels, since we are drawing in vector form,\n",
    "                        # we need to draw horizontal lines on the image\n",
    "                        x_start = trunc(\n",
    "                            trunc(px / image_height) * adjusted_ratio)\n",
    "                        y_start = trunc(px % image_height * adjusted_ratio)\n",
    "                        px += counts\n",
    "                        x_end = trunc(trunc(px / image_height)\n",
    "                                      * adjusted_ratio)\n",
    "                        y_end = trunc(px % image_height * adjusted_ratio)\n",
    "                        if x_end == x_start:\n",
    "                            # This is only on one line\n",
    "                            rle_list.append(\n",
    "                                {'x': x_start, 'y': y_start, 'width': 1, 'height': (y_end - y_start)})\n",
    "                        if x_end > x_start:\n",
    "                            # This spans more than one line\n",
    "                            # Insert top line first\n",
    "                            rle_list.append(\n",
    "                                {'x': x_start, 'y': y_start, 'width': 1, 'height': (image_height - y_start)})\n",
    "\n",
    "                            # Insert middle lines if needed\n",
    "                            lines_spanned = x_end - x_start + 1  # total number of lines spanned\n",
    "                            full_lines_to_insert = lines_spanned - 2\n",
    "                            if full_lines_to_insert > 0:\n",
    "                                full_lines_to_insert = trunc(\n",
    "                                    full_lines_to_insert * adjusted_ratio)\n",
    "                                rle_list.append(\n",
    "                                    {'x': (x_start + 1), 'y': 0, 'width': full_lines_to_insert, 'height': image_height})\n",
    "\n",
    "                            # Insert bottom line\n",
    "                            rle_list.append(\n",
    "                                {'x': x_end, 'y': 0, 'width': 1, 'height': y_end})\n",
    "                if len(rle_list) > 0:\n",
    "                    rle_regions[segm['id']] = rle_list\n",
    "            else:\n",
    "                # Add the polygon segmentation\n",
    "                for segmentation_points in segm['segmentation']:\n",
    "                    segmentation_points = np.multiply(\n",
    "                        segmentation_points, adjusted_ratio).astype(int)\n",
    "                    polygons_list.append(\n",
    "                        str(segmentation_points).lstrip('[').rstrip(']'))\n",
    "            polygons[segm['id']] = polygons_list\n",
    "            if i < len(self.colors):\n",
    "                poly_colors[segm['id']] = self.colors[i]\n",
    "            else:\n",
    "                poly_colors[segm['id']] = 'white'\n",
    "\n",
    "            bbox = segm['bbox']\n",
    "            bbox_points = [bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1],\n",
    "                           bbox[0] + bbox[2], bbox[1] +\n",
    "                           bbox[3], bbox[0], bbox[1] + bbox[3],\n",
    "                           bbox[0], bbox[1]]\n",
    "            bbox_points = np.multiply(bbox_points, adjusted_ratio).astype(int)\n",
    "            bbox_polygons[segm['id']] = str(\n",
    "                bbox_points).lstrip('[').rstrip(']')\n",
    "            bbox_categories[segm['id']] = self.categories[segm['category_id']]\n",
    "            # Print details\n",
    "            print('    {}:{}:{}'.format(\n",
    "                segm['id'], poly_colors[segm['id']], self.categories[segm['category_id']]))\n",
    "\n",
    "        # Draw segmentation polygons on image\n",
    "        html = '<div class=\"container\" style=\"position:relative;\">'\n",
    "        html += '<img src=\"{}\" style=\"position:relative;top:0px;left:0px;width:{}px;\">'.format(\n",
    "            image_path, adjusted_width)\n",
    "        html += '<div class=\"svgclass\"><svg width=\"{}\" height=\"{}\">'.format(\n",
    "            adjusted_width, adjusted_height)\n",
    "\n",
    "        if show_polys:\n",
    "            for seg_id, points_list in polygons.items():\n",
    "                fill_color = poly_colors[seg_id]\n",
    "                stroke_color = poly_colors[seg_id]\n",
    "                for points in points_list:\n",
    "                    html += '<polygon points=\"{}\" style=\"fill:{}; stroke:{}; stroke-width:1; fill-opacity:0.5\" />'.format(\n",
    "                        points, fill_color, stroke_color)\n",
    "\n",
    "        if show_crowds:\n",
    "            for seg_id, rect_list in rle_regions.items():\n",
    "                fill_color = poly_colors[seg_id]\n",
    "                stroke_color = poly_colors[seg_id]\n",
    "                for rect_def in rect_list:\n",
    "                    x, y = rect_def['x'], rect_def['y']\n",
    "                    w, h = rect_def['width'], rect_def['height']\n",
    "                    html += '<rect x=\"{}\" y=\"{}\" width=\"{}\" height=\"{}\" style=\"fill:{}; stroke:{}; stroke-width:1; fill-opacity:0.5; stroke-opacity:0.5\" />'.format(\n",
    "                        x, y, w, h, fill_color, stroke_color)\n",
    "\n",
    "        if show_bbox:\n",
    "            for seg_id, points in bbox_polygons.items():\n",
    "                x, y = [int(i) for i in points.split()[:2]]\n",
    "                html += '<text x=\"{}\" y=\"{}\" fill=\"yellow\">{}</text>'.format(\n",
    "                    x, y, bbox_categories[seg_id][\"name\"])\n",
    "                fill_color = poly_colors[seg_id]\n",
    "                stroke_color = poly_colors[seg_id]\n",
    "                html += '<polygon points=\"{}\" style=\"fill:{}; stroke:{}; stroke-width:1; fill-opacity:0\" />'.format(\n",
    "                    points, fill_color, stroke_color)\n",
    "\n",
    "        html += '</svg></div>'\n",
    "        html += '</div>'\n",
    "        html += '<style>'\n",
    "        html += '.svgclass { position:absolute; top:0px; left:0px;}'\n",
    "        html += '</style>'\n",
    "        return html\n",
    "\n",
    "    def process_info(self):\n",
    "        self.info = self.coco.get('info')\n",
    "\n",
    "    def process_licenses(self):\n",
    "        self.licenses = self.coco.get('licenses')\n",
    "\n",
    "    def process_categories(self):\n",
    "        self.categories = {}\n",
    "        self.super_categories = {}\n",
    "        for category in self.coco['categories']:\n",
    "            cat_id = category['id']\n",
    "            super_category = category['supercategory']\n",
    "\n",
    "            # Add category to the categories dict\n",
    "            if cat_id not in self.categories:\n",
    "                self.categories[cat_id] = category\n",
    "            else:\n",
    "                print(\"ERROR: Skipping duplicate category id: {}\".format(category))\n",
    "\n",
    "            # Add category to super_categories dict\n",
    "            if super_category not in self.super_categories:\n",
    "                # Create a new set with the category id\n",
    "                self.super_categories[super_category] = {cat_id}\n",
    "            else:\n",
    "                self.super_categories[super_category] |= {\n",
    "                    cat_id}  # Add category id to the set\n",
    "\n",
    "    def process_images(self):\n",
    "        self.images = {}\n",
    "        for image in self.coco['images']:\n",
    "            image_id = image['id']\n",
    "            if image_id in self.images:\n",
    "                print(\"ERROR: Skipping duplicate image id: {}\".format(image))\n",
    "            else:\n",
    "                self.images[image_id] = image\n",
    "\n",
    "    def process_segmentations(self):\n",
    "        self.segmentations = {}\n",
    "        for segmentation in self.coco['annotations']:\n",
    "            image_id = segmentation['image_id']\n",
    "            if image_id not in self.segmentations:\n",
    "                self.segmentations[image_id] = []\n",
    "            self.segmentations[image_id].append(segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "=============\n",
      "  description: ImmersiveLimit Cigarette Butt Dataset\n",
      "  url: http://www.immersivelimit.com\n",
      "  version: 0.1\n",
      "  year: 2018\n",
      "  contributor: Adam Kelly\n",
      "  date_created: 2018/07/27\n",
      "\n",
      "Licenses:\n",
      "=========\n",
      "  url: http://www.immersivelimit.com/noncommercial-educational-license-agreement\n",
      "  id: 0\n",
      "  name: ImmersiveLimit.com Non-Commercial, Educational License Agreement\n",
      "\n",
      "\n",
      "Categories:\n",
      "=========\n",
      "  super_category: litter\n",
      "    id 1: cig_butt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "annotation_path = './train/coco_annotations.json'\n",
    "image_dir = './train/images'\n",
    "\n",
    "coco_dataset = CocoDataset(annotation_path, image_dir)\n",
    "coco_dataset.display_info()\n",
    "coco_dataset.display_licenses()\n",
    "coco_dataset.display_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:\n",
      "======\n",
      "  license: 0\n",
      "  file_name: 00000002.jpg\n",
      "  width: 512\n",
      "  height: 512\n",
      "  id: 2\n",
      "  segmentations (1):\n",
      "    2:blue:{'supercategory': 'litter', 'id': 1, 'name': 'cig_butt'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"container\" style=\"position:relative;\"><img src=\"./train/images/00000002.jpg\" style=\"position:relative;top:0px;left:0px;width:512px;\"><div class=\"svgclass\"><svg width=\"512\" height=\"512.0\"><polygon points=\"378 317 405 283 405 281 396 273 395 267 387 275 378 287 376 292 366 302\n",
       " 367 307 378 317\" style=\"fill:blue; stroke:blue; stroke-width:1; fill-opacity:0.5\" /><text x=\"366\" y=\"267\" fill=\"yellow\">cig_butt</text><polygon points=\"366 267 405 267 405 317 366 317 366 267\" style=\"fill:blue; stroke:blue; stroke-width:1; fill-opacity:0\" /></svg></div></div><style>.svgclass { position:absolute; top:0px; left:0px;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = coco_dataset.display_image(2, use_url=False)\n",
    "IPython.display.HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycocotools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-75b2678e02a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpycocotools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoco\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCOCO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pycocotools'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'cocoapi'...\n"
     ]
    }
   ],
   "source": [
    "!git clone git://github.com/philferriere/cocoapi.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\pluu\\servicebot\\cocoapi\\pythonapi\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (setup.py): started\n",
      "  Building wheel for pycocotools (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pycocotools\n",
      "Failed to build pycocotools\n",
      "Installing collected packages: pycocotools\n",
      "  Running setup.py install for pycocotools: started\n",
      "    Running setup.py install for pycocotools: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Complete output from command 'C:\\Users\\pluu\\.conda\\envs\\pluu\\python.exe' -u -c 'import setuptools, tokenize;__file__='\"'\"'C:\\\\Users\\\\pluu\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-ypsvd7fw\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\pluu\\AppData\\Local\\Temp\\pip-wheel-t8yv_h2y' --python-tag cp37:\n",
      "  ERROR: running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.7\n",
      "  creating build\\lib.win-amd64-3.7\\pycocotools\n",
      "  copying pycocotools\\coco.py -> build\\lib.win-amd64-3.7\\pycocotools\n",
      "  copying pycocotools\\cocoeval.py -> build\\lib.win-amd64-3.7\\pycocotools\n",
      "  copying pycocotools\\mask.py -> build\\lib.win-amd64-3.7\\pycocotools\n",
      "  copying pycocotools\\__init__.py -> build\\lib.win-amd64-3.7\\pycocotools\n",
      "  running build_ext\n",
      "  building 'pycocotools._mask' extension\n",
      "  error: Microsoft Visual C++ 14.0 is required. Get it with \"Microsoft Visual C++ Build Tools\": https://visualstudio.microsoft.com/downloads/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for pycocotools\n",
      "    ERROR: Complete output from command 'C:\\Users\\pluu\\.conda\\envs\\pluu\\python.exe' -u -c 'import setuptools, tokenize;__file__='\"'\"'C:\\\\Users\\\\pluu\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-ypsvd7fw\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\pluu\\AppData\\Local\\Temp\\pip-record-js94uvxp\\install-record.txt' --single-version-externally-managed --compile:\n",
      "    ERROR: running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.7\n",
      "    creating build\\lib.win-amd64-3.7\\pycocotools\n",
      "    copying pycocotools\\coco.py -> build\\lib.win-amd64-3.7\\pycocotools\n",
      "    copying pycocotools\\cocoeval.py -> build\\lib.win-amd64-3.7\\pycocotools\n",
      "    copying pycocotools\\mask.py -> build\\lib.win-amd64-3.7\\pycocotools\n",
      "    copying pycocotools\\__init__.py -> build\\lib.win-amd64-3.7\\pycocotools\n",
      "    running build_ext\n",
      "    building 'pycocotools._mask' extension\n",
      "    error: Microsoft Visual C++ 14.0 is required. Get it with \"Microsoft Visual C++ Build Tools\": https://visualstudio.microsoft.com/downloads/\n",
      "    ----------------------------------------\n",
      "ERROR: Command \"'C:\\Users\\pluu\\.conda\\envs\\pluu\\python.exe' -u -c 'import setuptools, tokenize;__file__='\"'\"'C:\\\\Users\\\\pluu\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-ypsvd7fw\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\pluu\\AppData\\Local\\Temp\\pip-record-js94uvxp\\install-record.txt' --single-version-externally-managed --compile\" failed with error code 1 in C:\\Users\\pluu\\AppData\\Local\\Temp\\pip-req-build-ypsvd7fw\\\n"
     ]
    }
   ],
   "source": [
    "!pip install ./cocoapi/PythonAPI/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools import mask as maskUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mrcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config', 'model', 'parallel_model', 'utils', 'visualize']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.list_modules(mrcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/phatluu'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.expanduser('~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 6s 1us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       "  array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)),\n",
       " (array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       "  array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 17188001956992830561, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 6698093773\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 8792224307317502543\n",
       " physical_device_desc: \"device: 0, name: Quadro P4000, pci bus id: 0000:01:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device Name: /device:GPU:0\n",
      "Memory: 6.698093773(GB)\n",
      "Physical Device: device: 0, name: Quadro P4000, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "device_list = device_lib.list_local_devices()\n",
    "for d in device_list:\n",
    "    if d.device_type == 'GPU':\n",
    "        memory = d.memory_limit/1e9\n",
    "        print('Device Name: {}'.format(d.name))\n",
    "        print('Memory: {}(GB)'.format(memory))\n",
    "        print('Physical Device: {}'.format(d.physical_device_desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from skimage import measure, io\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "from PIL import Image\n",
    "\n",
    "class InfoJsonUtils():\n",
    "    \"\"\" Creates an info object to describe a COCO dataset\n",
    "    \"\"\"\n",
    "    def create_coco_info(self, description, url, version, year, contributor, date_created):\n",
    "        \"\"\" Creates the \"info\" portion of COCO json\n",
    "        \"\"\"\n",
    "        info = dict()\n",
    "        info['description'] = description\n",
    "        info['url'] = url\n",
    "        info['version'] = version\n",
    "        info['year'] = year\n",
    "        info['contributor'] = contributor\n",
    "        info['date_created'] = date_created\n",
    "\n",
    "        return info\n",
    "\n",
    "class LicenseJsonUtils():\n",
    "    \"\"\" Creates a license object to describe a COCO dataset\n",
    "    \"\"\"\n",
    "    def create_coco_license(self, url, license_id, name):\n",
    "        \"\"\" Creates the \"licenses\" portion of COCO json\n",
    "        \"\"\"\n",
    "        lic = dict()\n",
    "        lic['url'] = url\n",
    "        lic['id'] = license_id\n",
    "        lic['name'] = name\n",
    "\n",
    "        return lic\n",
    "\n",
    "class CategoryJsonUtils():\n",
    "    \"\"\" Creates a category object to describe a COCO dataset\n",
    "    \"\"\"\n",
    "    def create_coco_category(self, supercategory, category_id, name):\n",
    "        category = dict()\n",
    "        category['supercategory'] = supercategory\n",
    "        category['id'] = category_id\n",
    "        category['name'] = name\n",
    "\n",
    "        return category\n",
    "\n",
    "class ImageJsonUtils():\n",
    "    \"\"\" Creates an image object to describe a COCO dataset\n",
    "    \"\"\"\n",
    "    def create_coco_image(self, image_path, image_id, image_license):\n",
    "        \"\"\" Creates the \"image\" portion of COCO json\n",
    "        \"\"\"\n",
    "        # Open the image and get the size\n",
    "        image_file = Image.open(image_path)\n",
    "        width, height = image_file.size\n",
    "\n",
    "        image = dict()\n",
    "        image['license'] = image_license\n",
    "        image['file_name'] = image_path.name\n",
    "        image['width'] = width\n",
    "        image['height'] = height\n",
    "        image['id'] = image_id\n",
    "\n",
    "        return image\n",
    "\n",
    "class AnnotationJsonUtils():\n",
    "    \"\"\" Creates an annotation object to describe a COCO dataset\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.annotation_id_index = 0\n",
    "\n",
    "    def create_coco_annotations(self, image_mask_path, image_id, category_ids):\n",
    "        \"\"\" Takes a pixel-based RGB image mask and creates COCO annotations.\n",
    "        Args:\n",
    "            image_mask_path: a pathlib.Path to the image mask\n",
    "            image_id: the integer image id\n",
    "            category_ids: a dictionary of integer category ids keyed by RGB color (a tuple converted to a string)\n",
    "                e.g. {'(255, 0, 0)': {'category': 'owl', 'super_category': 'bird'} }\n",
    "        Returns:\n",
    "            annotations: a list of COCO annotation dictionaries that can\n",
    "            be converted to json. e.g.:\n",
    "            {\n",
    "                \"segmentation\": [[101.79,307.32,69.75,281.11,...,100.05,309.66]],\n",
    "                \"area\": 51241.3617,\n",
    "                \"iscrowd\": 0,\n",
    "                \"image_id\": 284725,\n",
    "                \"bbox\": [68.01,134.89,433.41,174.77],\n",
    "                \"category_id\": 6,\n",
    "                \"id\": 165690\n",
    "            }\n",
    "        \"\"\"\n",
    "        # Set class variables\n",
    "        self.image_id = image_id\n",
    "        self.category_ids = category_ids\n",
    "\n",
    "        # Make sure keys in category_ids are strings\n",
    "        for key in self.category_ids.keys():\n",
    "            if type(key) is not str:\n",
    "                raise TypeError('category_ids keys must be strings (e.g. \"(0, 0, 255)\")')\n",
    "            break\n",
    "\n",
    "        # Open and process image\n",
    "        self.mask_image = Image.open(image_mask_path)\n",
    "        self.mask_image = self.mask_image.convert('RGB')\n",
    "        self.width, self.height = self.mask_image.size\n",
    "\n",
    "        # Split up the multi-colored masks into multiple 0/1 bit masks\n",
    "        self._isolate_masks()\n",
    "\n",
    "        # Create annotations from the masks\n",
    "        self._create_annotations()\n",
    "\n",
    "        return self.annotations\n",
    "\n",
    "    def _isolate_masks(self):\n",
    "        # Breaks mask up into isolated masks based on color\n",
    "\n",
    "        self.isolated_masks = dict()\n",
    "        for x in range(self.width):\n",
    "            for y in range(self.height):\n",
    "                pixel_rgb = self.mask_image.getpixel((x,y))\n",
    "                pixel_rgb_str = str(pixel_rgb)\n",
    "\n",
    "                # If the pixel is any color other than black, add it to a respective isolated image mask\n",
    "                if not pixel_rgb == (0, 0, 0):\n",
    "                    if self.isolated_masks.get(pixel_rgb_str) is None:\n",
    "                        # Isolated mask doesn't have its own image yet, create one\n",
    "                        # with 1-bit pixels, default black. Make room for 1 pixel of\n",
    "                        # padding on each edge to allow the contours algorithm to work\n",
    "                        # when shapes bleed up to the edge\n",
    "                        self.isolated_masks[pixel_rgb_str] = Image.new('1', (self.width + 2, self.height + 2))\n",
    "\n",
    "                    # Add the pixel to the mask image, shifting by 1 pixel to account for padding\n",
    "                    self.isolated_masks[pixel_rgb_str].putpixel((x + 1, y + 1), 1)\n",
    "\n",
    "    def _create_annotations(self):\n",
    "        # Creates annotations for each isolated mask\n",
    "\n",
    "        # Each image may have multiple annotations, so create an array\n",
    "        self.annotations = []\n",
    "        for key, mask in self.isolated_masks.items():\n",
    "            annotation = dict()\n",
    "            annotation['segmentation'] = []\n",
    "            annotation['iscrowd'] = 0\n",
    "            annotation['image_id'] = self.image_id\n",
    "            if not self.category_ids.get(key):\n",
    "                print(f'category color not found: {key}; check for missing category or antialiasing')\n",
    "                continue\n",
    "            annotation['category_id'] = self.category_ids[key]\n",
    "            annotation['id'] = self._next_annotation_id()\n",
    "\n",
    "            # Find contours in the isolated mask\n",
    "            contours = measure.find_contours(mask, 0.5, positive_orientation='low')\n",
    "\n",
    "            polygons = []\n",
    "            for contour in contours:\n",
    "                # Flip from (row, col) representation to (x, y)\n",
    "                # and subtract the padding pixel\n",
    "                for i in range(len(contour)):\n",
    "                    row, col = contour[i]\n",
    "                    contour[i] = (col - 1, row - 1)\n",
    "\n",
    "                # Make a polygon and simplify it\n",
    "                poly = Polygon(contour)\n",
    "                poly = poly.simplify(1.0, preserve_topology=False)\n",
    "\n",
    "                if (poly.area > 16): # Ignore tiny polygons\n",
    "                    if (poly.geom_type == 'MultiPolygon'):\n",
    "                        # if MultiPolygon, take the smallest convex Polygon containing all the points in the object\n",
    "                        poly = poly.convex_hull\n",
    "\n",
    "                    if (poly.geom_type == 'Polygon'): # Ignore if still not a Polygon (could be a line or point)\n",
    "                        polygons.append(poly)\n",
    "                        segmentation = np.array(poly.exterior.coords).ravel().tolist()\n",
    "                        annotation['segmentation'].append(segmentation)\n",
    "\n",
    "            if len(polygons) == 0:\n",
    "                # This item doesn't have any visible polygons, ignore it\n",
    "                # (This can happen if a randomly placed foreground is covered up\n",
    "                #  by other foregrounds)\n",
    "                continue\n",
    "\n",
    "            # Combine the polygons to calculate the bounding box and area\n",
    "            multi_poly = MultiPolygon(polygons)\n",
    "            x, y, max_x, max_y = multi_poly.bounds\n",
    "            self.width = max_x - x\n",
    "            self.height = max_y - y\n",
    "            annotation['bbox'] = (x, y, self.width, self.height)\n",
    "            annotation['area'] = multi_poly.area\n",
    "\n",
    "            # Finally, add this annotation to the list\n",
    "            self.annotations.append(annotation)\n",
    "\n",
    "    def _next_annotation_id(self):\n",
    "        # Gets the next annotation id\n",
    "        # Note: This is not a unique id. It simply starts at 0 and increments each time it is called\n",
    "\n",
    "        a_id = self.annotation_id_index\n",
    "        self.annotation_id_index += 1\n",
    "        return a_id\n",
    "\n",
    "class CocoJsonCreator():\n",
    "    def validate_and_process_args(self, args):\n",
    "        \"\"\" Validates the arguments coming in from the command line and performs\n",
    "            initial processing\n",
    "        Args:\n",
    "            args: ArgumentParser arguments\n",
    "        \"\"\"\n",
    "        # Validate the mask definition file exists\n",
    "        mask_definition_file = Path(args.mask_definition)\n",
    "        if not (mask_definition_file.exists and mask_definition_file.is_file()):\n",
    "            raise FileNotFoundError(f'mask definition file was not found: {mask_definition_file}')\n",
    "\n",
    "        # Load the mask definition json\n",
    "        with open(mask_definition_file) as json_file:\n",
    "            self.mask_definitions = json.load(json_file)\n",
    "\n",
    "        self.dataset_dir = mask_definition_file.parent\n",
    "\n",
    "        # Validate the dataset info file exists\n",
    "        dataset_info_file = Path(args.dataset_info)\n",
    "        if not (dataset_info_file.exists() and dataset_info_file.is_file()):\n",
    "            raise FileNotFoundError(f'dataset info file was not found: {dataset_info_file}')\n",
    "\n",
    "        # Load the dataset info json\n",
    "        with open(dataset_info_file) as json_file:\n",
    "            self.dataset_info = json.load(json_file)\n",
    "\n",
    "        assert 'info' in self.dataset_info, 'dataset_info JSON was missing \"info\"'\n",
    "        assert 'license' in self.dataset_info, 'dataset_info JSON was missing \"license\"'\n",
    "\n",
    "    def create_info(self):\n",
    "        \"\"\" Creates the \"info\" piece of the COCO json\n",
    "        \"\"\"\n",
    "        info_json = self.dataset_info['info']\n",
    "        iju = InfoJsonUtils()\n",
    "        return iju.create_coco_info(\n",
    "            description = info_json['description'],\n",
    "            version = info_json['version'],\n",
    "            url = info_json['url'],\n",
    "            year = info_json['year'],\n",
    "            contributor = info_json['contributor'],\n",
    "            date_created = info_json['date_created']\n",
    "        )\n",
    "\n",
    "    def create_licenses(self):\n",
    "        \"\"\" Creates the \"license\" portion of the COCO json\n",
    "        \"\"\"\n",
    "        license_json = self.dataset_info['license']\n",
    "        lju = LicenseJsonUtils()\n",
    "        lic = lju.create_coco_license(\n",
    "            url = license_json['url'],\n",
    "            license_id = license_json['id'],\n",
    "            name = license_json['name']\n",
    "        )\n",
    "        return [lic]\n",
    "\n",
    "    def create_categories(self):\n",
    "        \"\"\" Creates the \"categories\" portion of the COCO json\n",
    "        Returns:\n",
    "            categories: category objects that become part of the final json\n",
    "            category_ids_by_name: a lookup dictionary for category ids based\n",
    "                on the name of the category\n",
    "        \"\"\"\n",
    "        cju = CategoryJsonUtils()\n",
    "        categories = []\n",
    "        category_ids_by_name = dict()\n",
    "        category_id = 1 # 0 is reserved for the background\n",
    "\n",
    "        super_categories = self.mask_definitions['super_categories']\n",
    "        for super_category, _categories in super_categories.items():\n",
    "            for category_name in _categories:\n",
    "                categories.append(cju.create_coco_category(super_category, category_id, category_name))\n",
    "                category_ids_by_name[category_name] = category_id\n",
    "                category_id += 1\n",
    "\n",
    "        return categories, category_ids_by_name\n",
    "\n",
    "    def create_images_and_annotations(self, category_ids_by_name):\n",
    "        \"\"\" Creates the list of images (in json) and the annotations for each\n",
    "            image for the \"image\" and \"annotations\" portions of the COCO json\n",
    "        \"\"\"\n",
    "        iju = ImageJsonUtils()\n",
    "        aju = AnnotationJsonUtils()\n",
    "\n",
    "        image_objs = []\n",
    "        annotation_objs = []\n",
    "        image_license = self.dataset_info['license']['id']\n",
    "        image_id = 0\n",
    "\n",
    "        mask_count = len(self.mask_definitions['masks'])\n",
    "        print(f'Processing {mask_count} mask definitions...')\n",
    "\n",
    "        # For each mask definition, create image and annotations\n",
    "        for file_name, mask_def in tqdm(self.mask_definitions['masks'].items()):\n",
    "            # Create a coco image json item\n",
    "            image_path = Path(self.dataset_dir) / file_name\n",
    "            image_obj = iju.create_coco_image(\n",
    "                image_path,\n",
    "                image_id,\n",
    "                image_license)\n",
    "            image_objs.append(image_obj)\n",
    "\n",
    "            mask_path = Path(self.dataset_dir) / mask_def['mask']\n",
    "\n",
    "            # Create a dict of category ids keyed by rgb_color\n",
    "            category_ids_by_rgb = dict()\n",
    "            for rgb_color, category in mask_def['color_categories'].items():\n",
    "                category_ids_by_rgb[rgb_color] = category_ids_by_name[category['category']]\n",
    "            annotation_obj = aju.create_coco_annotations(mask_path, image_id, category_ids_by_rgb)\n",
    "            annotation_objs += annotation_obj # Add the new annotations to the existing list\n",
    "            image_id += 1\n",
    "\n",
    "        return image_objs, annotation_objs\n",
    "\n",
    "    def main(self, args):\n",
    "        self.validate_and_process_args(args)\n",
    "\n",
    "        info = self.create_info()\n",
    "        licenses = self.create_licenses()\n",
    "        categories, category_ids_by_name = self.create_categories()\n",
    "        images, annotations = self.create_images_and_annotations(category_ids_by_name)\n",
    "\n",
    "        master_obj = {\n",
    "            'info': info,\n",
    "            'licenses': licenses,\n",
    "            'images': images,\n",
    "            'annotations': annotations,\n",
    "            'categories': categories\n",
    "        }\n",
    "\n",
    "        # Write the json to a file\n",
    "        output_path = Path(self.dataset_dir) / 'coco_instances.json'\n",
    "        with open(output_path, 'w+') as output_file:\n",
    "            json.dump(master_obj, output_file)\n",
    "\n",
    "        print(f'Annotations successfully written to file:\\n{output_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "json_filepath = os.path.join(os.getcwd(),'Downloads\\\\coco_annotations.json')\n",
    "with open(json_filepath) as fid:\n",
    "    json_obj = json.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['info', 'licenses', 'images', 'annotations', 'categories'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_obj.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'ImmersiveLimit Cigarette Butt Dataset',\n",
       " 'url': 'http://www.immersivelimit.com',\n",
       " 'version': '0.1',\n",
       " 'year': 2018,\n",
       " 'contributor': 'Adam Kelly',\n",
       " 'date_created': '2018/07/27'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_obj.get('info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'http://www.immersivelimit.com/noncommercial-educational-license-agreement',\n",
       "  'id': 0,\n",
       "  'name': 'ImmersiveLimit.com Non-Commercial, Educational License Agreement'}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_obj.get('licenses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'supercategory': 'litter', 'id': 1, 'name': 'cig_butt'}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_obj.get('categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_obj.get('images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'license': 0,\n",
       " 'file_name': '00000000.jpg',\n",
       " 'width': 512,\n",
       " 'height': 512,\n",
       " 'id': 0}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_obj.get('images')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_obj.get('annotations'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segmentation': [[344.0,\n",
       "   427.5,\n",
       "   367.0,\n",
       "   412.5,\n",
       "   388.0,\n",
       "   401.5,\n",
       "   392.0,\n",
       "   397.5,\n",
       "   395.0,\n",
       "   397.5,\n",
       "   404.0,\n",
       "   392.5,\n",
       "   406.5,\n",
       "   390.0,\n",
       "   406.5,\n",
       "   387.0,\n",
       "   402.5,\n",
       "   380.0,\n",
       "   397.0,\n",
       "   375.5,\n",
       "   389.0,\n",
       "   376.5,\n",
       "   385.0,\n",
       "   380.5,\n",
       "   363.0,\n",
       "   391.5,\n",
       "   335.0,\n",
       "   410.5,\n",
       "   331.0,\n",
       "   411.5,\n",
       "   329.5,\n",
       "   415.0,\n",
       "   335.0,\n",
       "   417.5,\n",
       "   338.5,\n",
       "   421.0,\n",
       "   340.5,\n",
       "   426.0,\n",
       "   344.0,\n",
       "   427.5]],\n",
       " 'iscrowd': 0,\n",
       " 'image_id': 0,\n",
       " 'category_id': 1,\n",
       " 'id': 0,\n",
       " 'bbox': [329.5, 375.5, 77.0, 52.0],\n",
       " 'area': 1510.5}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_obj.get('annotations')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
